{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from requests import get\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, file_name):\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        response = get(url)\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mnist(images_path: str, labels_path: str):\n",
    "    with gzip.open(labels_path, 'rb') as labelsFile:\n",
    "        labels = np.frombuffer(labelsFile.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(images_path,'rb') as imagesFile:\n",
    "        length = len(labels)\n",
    "        # Load flat 28x28 px images (784 px), and convert them to 28x28 px\n",
    "        features = np.frombuffer(imagesFile.read(), dtype=np.uint8, offset=16) \\\n",
    "                        .reshape(length, 784) \\\n",
    "                        .reshape(length, 28, 28, 1)\n",
    "        \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', 'MNIST/train-images-idx3-ubyte.gz')\n",
    "download_file('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', 'MNIST/train-labels-idx1-ubyte.gz')\n",
    "download_file('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', 'MNIST/t10k-images-idx3-ubyte.gz')\n",
    "download_file('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', 'MNIST/t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {}\n",
    "test = {}\n",
    "validation = {}\n",
    "\n",
    "train['features'], train['labels'] = read_mnist('MNIST/train-images-idx3-ubyte.gz', 'MNIST/train-labels-idx1-ubyte.gz')\n",
    "test['features'], test['labels'] = read_mnist('MNIST/t10k-images-idx3-ubyte.gz', 'MNIST/t10k-labels-idx1-ubyte.gz')\n",
    "train['features'], train['labels'] = shuffle(train['features'], train['labels'])\n",
    "train['features'], validation['features'], train['labels'], validation['labels'] = train_test_split(train['features'], train['labels'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['features'] = np.pad(train['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "validation['features'] = np.pad(validation['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "test['features'] = np.pad(test['features'], ((0,0),(2,2),(2,2),(0,0)), 'constant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create virtual concept drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 2, 0, ..., 8, 8, 4], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create concept drift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)))\n",
    "model.add(tf.keras.layers.AveragePooling2D())\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(tf.keras.layers.AveragePooling2D())\n",
    "\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.add(tf.keras.layers.Dense(units=120, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=84, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=10, activation = 'softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 14s 297us/sample - loss: 0.0105 - accuracy: 0.9970 - val_loss: 0.0685 - val_accuracy: 0.9865\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 13s 269us/sample - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0785 - val_accuracy: 0.9866\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 13s 274us/sample - loss: 0.0071 - accuracy: 0.9977 - val_loss: 0.0922 - val_accuracy: 0.9844\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 14s 287us/sample - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0845 - val_accuracy: 0.9871\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 12s 256us/sample - loss: 0.0071 - accuracy: 0.9980 - val_loss: 0.0971 - val_accuracy: 0.9854\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 12s 254us/sample - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1355 - val_accuracy: 0.9779\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 12s 253us/sample - loss: 0.0059 - accuracy: 0.9983 - val_loss: 0.1031 - val_accuracy: 0.9855\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 12s 256us/sample - loss: 0.0049 - accuracy: 0.9986 - val_loss: 0.1033 - val_accuracy: 0.9868\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 12s 259us/sample - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.0990 - val_accuracy: 0.9872\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 12s 254us/sample - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.1057 - val_accuracy: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f88f2f04b70>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train['features'], train['labels'], batch_size=128, epochs=10, validation_data=(validation['features'], validation['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09057514399004883, 0.9891]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test['features'], test['labels'], batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LeNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
